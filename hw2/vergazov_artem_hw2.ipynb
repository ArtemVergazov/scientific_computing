{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XDBefNIgZE7"
   },
   "source": [
    "## Scientific Computing 2021: Homework Assignment 2 \n",
    "Due Monday October 18, 2021 (23:59)\n",
    "\n",
    "### Problem 1 (2 points)\n",
    "Let $A_q=\\left(\\begin{matrix}1 & q\\\\ 0 & 1\\end{matrix}\\right)$ with $q\\in\\mathbb R$. \n",
    "* For any $q$, find condition number $\\kappa(A_q)$ with respect to the $l^2$-norm.\n",
    "* Give an example of specific values of $q,\\mathbf b, \\Delta\\mathbf b$ such that, when solving $A_q\\mathbf x = \\mathbf b$ and $A_q(\\mathbf x+\\Delta \\mathbf x)=\\mathbf b +\\Delta\\mathbf b$, we get \n",
    "\n",
    "$$\\frac{\\|\\Delta \\mathbf x\\|}{\\|\\mathbf x\\|}\\ge 10^6\\frac{\\|\\Delta\\mathbf b\\|}{\\|\\mathbf b\\|}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\|\\cdot\\|$ is the $l^2$-norm and $A_q$ is arbitrary, then $$\\kappa(A_q)=\\sqrt{\\frac{\\lambda_{\\max}(A_q^*A_q)}{\\lambda_{\\min}(A_q^*A_q)}}$$\n",
    "\n",
    "$$A_q^* A_q = \\left(\\begin{matrix}1 & q\\\\ q & 1 + q^2\\end{matrix}\\right)$$\n",
    "\n",
    "Eigenvals:\n",
    "$$\\begin{vmatrix} 1 - \\lambda & q \\\\ q & 1 + q^2 - \\lambda \\end{vmatrix} = \\lambda^2 - \\lambda(q^2 + 2) + 1 = 0$$\n",
    "\n",
    "$$\\lambda_{1, 2} = \\frac{\\pm q\\sqrt{q^2 + 4} + q^2 + 2}{2} \\in \\mathbb R$$\n",
    "\n",
    "$$\\kappa(A_q) = \\sqrt{\\frac{\\lambda_\\max}{\\lambda_\\min}} = \\sqrt{\\frac{|q|\\sqrt{q^2 + 4} + q^2 + 2}{-|q|\\sqrt{q^2 + 4} + q^2 + 2}} = \\frac{|q|\\sqrt{q^2 + 4} + q^2 + 2}{\\sqrt{(q^2 + 2)^2 - q^2(q^2 + 4)}} = \\frac{|q|\\sqrt{q^2 + 4} + q^2 + 2}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left(\\begin{matrix}1 & q \\\\ 0 & 1\\end{matrix}\\right) \\left(\\begin{matrix}x_1 \\\\ x_2 \\end{matrix}\\right) = \\left(\\begin{matrix}b_1 \\\\ b_2 \\end{matrix}\\right)$$\n",
    "\n",
    "$$\\left\\{\\begin{eqnarray} x_1 + q\\,x_2 & = & b_1 \\\\ x_2 & = & b_2 \\end{eqnarray}\\right.$$\n",
    "\n",
    "$$\\left\\{\\begin{eqnarray} x_1 & = & b_1 - q\\,b_2 \\\\ x_2 & = & b_2 \\end{eqnarray}\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSteps = 10\n",
    "qv = np.linspace(-100, 100, num=numSteps)\n",
    "b1v = np.linspace(-10, 10, num=numSteps)\n",
    "b2v = np.linspace(-10, 10, num=numSteps)\n",
    "db1v = np.linspace(-10, 10, num=numSteps)\n",
    "db2v = np.linspace(-10, 10, num=numSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in qv:\n",
    "    for b1 in b1v:\n",
    "        for b2 in b2v:\n",
    "            for db1 in db1v:\n",
    "                for db2 in db2v:\n",
    "                    if (\n",
    "    (db1 - q * db2)**2 + db2**2\n",
    ") / (\n",
    "    (b1 - q * b2)**2 + b2**2\n",
    ") >= 10**6 * (db1**2 + db2**2) / (b1**2 + b2**2):\n",
    "                        print(q, b1, b2, db1, db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relErr(v, dv):\n",
    "    return np.linalg.norm(dv) / np.linalg.norm(v)\n",
    "\n",
    "\n",
    "def solve(q, b):\n",
    "    return np.array([b[0] - q * b[1], b[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00999999500000375 0.000999999999899995\n",
      "True 9.9999950010038\n"
     ]
    }
   ],
   "source": [
    "db = np.array([10, 0])\n",
    "b = np.array([10000000001, 1000])\n",
    "q = 10000000\n",
    "\n",
    "x = solve(q, b)\n",
    "dx = solve(q, b + db) - x\n",
    "\n",
    "left = relErr(x, dx)\n",
    "right = 10**6 * relErr(b, db)\n",
    "print(left, right)\n",
    "print(left >= right, left / right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1, 1000], dtype=int64),\n",
       " array([10,  0], dtype=int64),\n",
       " array([  11, 1000], dtype=int64))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, dx, x + dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jKRLB72gZFE"
   },
   "source": [
    "### Problem 2 (2 points)\n",
    "* Write a program to compute an approximate value for the derivative of a function using the finite-difference formula \n",
    "\n",
    "  $$f'(x)\\approx \\frac{f(x+h)-f(x)}{h}.$$\n",
    "\n",
    "  Test your program using the function $\\tan(x)$ at $x=1$. Determine the error by comparing with the value obtained using the analytic derivative. Plot the magnitude of the error as a function of $h$, for $h=10^{-k}, k=0,\\ldots,16$. You should use log scale for $h$ and for the magnitude of the error. What is the minimum value of the error and at which $h$ is it achieved? Explain this result theoretically.\n",
    "* Repeat the exercise using the centered difference approximation\n",
    "\n",
    " $$f'(x)\\approx \\frac{f(x+h)-f(x-h)}{2h}.$$\n",
    "\n",
    " What is now different and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlohFH9bgZFG"
   },
   "source": [
    "### Problem 3 (2 points)\n",
    "* Implement regularized regression with an adaptive choice of regularization parameter. Your algorithm must accept the training data (`Xtrain`, `Ytrain`) and the input part of test data (`Xtest`), and output a prediction for test data (`Ypred`). You may use standard linear algebra libraries, but not specialized predictive modeling software (e.g., `scikit-learn`). Your algorithm should choose the regularization parameter by some optimization over a reasonable range of values and may use a sub-division of the training data into a train-in-train and a test-in-train components.\n",
    "* Test your algorithm on real data from UCI repository:\n",
    "  * https://archive.ics.uci.edu/ml/datasets/Relative+location+of+CT+slices+on+axial+axis\n",
    "  * https://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure\n",
    "  \n",
    "  Use random subsets of 300 rows as training sets, and the remaining rows as the test sets. Use the relative RMS error as the measure of accuracy.\n",
    "  Compare your results with results of some linear models implemented in standard predictive modeling software    (e.g., `Ridge` and `LinearRegression` from `scikit-learn`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l6EgKSAgZFI"
   },
   "source": [
    "### Problem 4 (2 points)\n",
    "Suppose that we use the Leapfrog algorithm with some $\\Delta t$ to simulate the dynamics of the harmonic oscillator (https://en.wikipedia.org/wiki/Harmonic_oscillator) with positive mass $m$ and force constant $k$ (in other words, with the energy function $H=\\frac{m\\dot x^2}{2}+\\frac{kx^2}{2}$). Assuming a perfect implementation of Leapfrog, at which combinations of $\\Delta t, m, k$ will the simulation diverge as $n\\to\\infty$, in the sense that $\\sup_n(\\tilde x_n^2+\\tilde v_{n+1/2}^2)=\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JlnITqYgZFJ"
   },
   "source": [
    "### Problem 5 (2 points)\n",
    "Consider the velocity Verlet method for solving the equation $\\frac{d}{dt}{x\\choose v}={v\\choose f_1(x)}$: \n",
    "\n",
    "\\begin{align}\n",
    "\\tilde v_{n+1/2} &= \\tilde v_{n}+\\frac{1}{2}f_1(\\tilde x_n)\\Delta t\\\\\n",
    "\\tilde x_{n+1} &= \\tilde x_{n}+\\tilde v_{n+1/2}\\Delta t\\\\\n",
    "\\tilde v_{n+1} &= \\tilde v_{n+1/2}+\\frac{1}{2}f_1(\\tilde x_{n+1})\\Delta t\n",
    "\\end{align}\n",
    "Find its global convergence order and verify it experimentally."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SciComp2021_HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
